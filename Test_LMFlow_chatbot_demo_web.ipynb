{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuaiyuZhang/DeepLearning/blob/main/Test_LMFlow_chatbot_demo_web.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the repo"
      ],
      "metadata": {
        "id": "6lrcgZnHHQUJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KddK4t-Wsl6n",
        "outputId": "e3cb12cc-46cb-40f4-d014-e63d68120743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LMFlow'...\n",
            "remote: Enumerating objects: 1077, done.\u001b[K\n",
            "remote: Counting objects: 100% (1052/1052), done.\u001b[K\n",
            "remote: Compressing objects: 100% (448/448), done.\u001b[K\n",
            "remote: Total 1077 (delta 515), reused 1001 (delta 499), pack-reused 25\u001b[K\n",
            "Receiving objects: 100% (1077/1077), 5.37 MiB | 23.48 MiB/s, done.\n",
            "Resolving deltas: 100% (516/516), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OptimalScale/LMFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqU73Xe7tWvO",
        "outputId": "02ff0163-2959-4a32-c31e-92d963b1c320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LMFlow\n"
          ]
        }
      ],
      "source": [
        "%cd ./LMFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This step will install all dependencies for runing the chatbot, it will take about 3 minutes."
      ],
      "metadata": {
        "id": "mGYFFSEDGFLc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvbPyWQvt5BW",
        "outputId": "a154ee27-7372-429a-e1e5-e8327c88f9e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/LMFlow\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting peft@ git+https://github.com/huggingface/peft@df0e1fb\n",
            "  Cloning https://github.com/huggingface/peft (to revision df0e1fb) to /tmp/pip-install-uwywgpe2/peft_0c3b0dd6277d41ef8598effece2e6d67\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft /tmp/pip-install-uwywgpe2/peft_0c3b0dd6277d41ef8598effece2e6d67\n",
            "\u001b[33m  WARNING: Did not find branch or tag 'df0e1fb', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running command git checkout -q df0e1fb\n",
            "  Resolved https://github.com/huggingface/peft to commit df0e1fb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trl@ git+https://github.com/lvwerra/trl.git#egg=trl-0.4.1\n",
            "  Cloning https://github.com/lvwerra/trl.git to /tmp/pip-install-uwywgpe2/trl_92dcdb776c864bbf8e6af6462435bc6d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lvwerra/trl.git /tmp/pip-install-uwywgpe2/trl_92dcdb776c864bbf8e6af6462435bc6d\n",
            "  Resolved https://github.com/lvwerra/trl.git to commit a2749d9e0c96198486b788875eda3b325f76a5c8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers@ git+https://github.com/huggingface/transformers@c612628\n",
            "  Cloning https://github.com/huggingface/transformers (to revision c612628) to /tmp/pip-install-uwywgpe2/transformers_d5f410dfbaae4c46bc10da15fdbc7df9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-install-uwywgpe2/transformers_d5f410dfbaae4c46bc10da15fdbc7df9\n",
            "\u001b[33m  WARNING: Did not find branch or tag 'c612628', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running command git checkout -q c612628\n",
            "  Resolved https://github.com/huggingface/transformers to commit c612628\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.24.2\n",
            "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==2.10.1\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from lmflow==0.0.1) (2.0.0+cu118)\n",
            "Collecting wandb==0.14.0\n",
            "  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed==0.8.3\n",
            "  Downloading deepspeed-0.8.3.tar.gz (765 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.4/765.4 KB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.9/dist-packages (from lmflow==0.0.1) (2.2.3)\n",
            "Collecting flask_cors\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->lmflow==0.0.1) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->lmflow==0.0.1) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->lmflow==0.0.1) (6.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->lmflow==0.0.1) (4.65.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->lmflow==0.0.1) (2.27.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->lmflow==0.0.1) (2023.3.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->lmflow==0.0.1) (1.4.4)\n",
            "Collecting hjson\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from deepspeed==0.8.3->lmflow==0.0.1) (5.9.4)\n",
            "Collecting py-cpuinfo\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from deepspeed==0.8.3->lmflow==0.0.1) (1.10.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->lmflow==0.0.1) (3.10.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->lmflow==0.0.1) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->lmflow==0.0.1) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->lmflow==0.0.1) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->lmflow==0.0.1) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->lmflow==0.0.1) (3.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb==0.14.0->lmflow==0.0.1) (1.4.4)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb==0.14.0->lmflow==0.0.1) (8.1.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb==0.14.0->lmflow==0.0.1) (3.20.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry-sdk-1.19.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.6/175.6 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb==0.14.0->lmflow==0.0.1) (67.6.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->lmflow==0.0.1) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->lmflow==0.0.1) (16.0.0)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from flask->lmflow==0.0.1) (2.1.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from flask->lmflow==0.0.1) (6.1.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from flask->lmflow==0.0.1) (2.2.3)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.9/dist-packages (from flask_cors->lmflow==0.0.1) (1.16.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 KB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers@ git+https://github.com/huggingface/transformers@c612628->lmflow==0.0.1) (2022.10.31)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->lmflow==0.0.1) (2.0.12)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->lmflow==0.0.1) (22.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6.0->flask->lmflow==0.0.1) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->lmflow==0.0.1) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.10.1->lmflow==0.0.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.10.1->lmflow==0.0.1) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.10.1->lmflow==0.0.1) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.10.1->lmflow==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.10.1->lmflow==0.0.1) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->lmflow==0.0.1) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: deepspeed, peft, transformers, trl, sentry-sdk, pathtools\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.8.3-py3-none-any.whl size=776426 sha256=6fd2f9352322e9587e76147a3635b67cfbbb40b6cd883e13ba8166746c79dc39\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/ea/8f/0768328ba436ed66f602d8d3b809624448c9eb627434176d04\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=40532 sha256=b59852b4c37259d7bdf5baa26297ae0d9d74333ac581b659b811e18c9e352beb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9zek1x3u/wheels/c2/29/9d/fbdfa853e1645f192e9a7a88afe996d4dc0a0a4f2ab1d729c1\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.28.0.dev0-py3-none-any.whl size=6858427 sha256=d5c3ab4ee17a7783b0db4dcaec59f9ab01e4ed409dce6cecb7d14a8ef2f281b8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9zek1x3u/wheels/65/9d/1b/5633348da899b76f9dcd50818d5f37a29471c37d1665e18dd6\n",
            "  Building wheel for trl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trl: filename=trl-0.4.2.dev0-py3-none-any.whl size=53628 sha256=1b1c4cb5237d90897b40529cbc68166e44cc3616c6b38ab953ca72f0469eb092\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9zek1x3u/wheels/ab/81/88/2e3ddd7591b397b560da92477ae2578b9b6f16f97a57ef49e1\n",
            "  Building wheel for sentry-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentry-sdk: filename=sentry_sdk-1.19.0-py2.py3-none-any.whl size=199169 sha256=2e04cca30a557a3b4e7c83f8a0649319b8e3ab9dd9f2506f1bee53980ccc8661\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/14/42/f56f4e523c47c35f7ee8b092eb0097aaa8d2fc001308153e2a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=80aea2d7236d8cf5bf1d3ad4bd7ceeabc8083e7d8551831dedbb55d29dd26c5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built deepspeed peft transformers trl sentry-sdk pathtools\n",
            "Installing collected packages: tokenizers, sentencepiece, py-cpuinfo, pathtools, ninja, hjson, xxhash, smmap, setproctitle, sentry-sdk, numpy, multidict, frozenlist, docker-pycreds, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, gitdb, aiosignal, transformers, GitPython, flask_cors, aiohttp, wandb, datasets, accelerate, trl, peft, deepspeed, lmflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Running setup.py develop for lmflow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.2 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.31 accelerate-0.18.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 deepspeed-0.8.3 dill-0.3.6 docker-pycreds-0.4.0 flask_cors-3.0.10 frozenlist-1.3.3 gitdb-4.0.10 hjson-3.1.0 huggingface-hub-0.13.3 lmflow-0.0.1 multidict-6.0.4 multiprocess-0.70.14 ninja-1.11.1 numpy-1.24.2 pathtools-0.1.2 peft-0.3.0.dev0 py-cpuinfo-9.0.0 responses-0.18.0 sentencepiece-0.1.97 sentry-sdk-1.19.0 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.2 transformers-4.28.0.dev0 trl-0.4.2.dev0 wandb-0.14.0 xxhash-3.2.0 yarl-1.8.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp39-cp39-linux_x86_64.whl size=3380633 sha256=a9f95a6a0ed3cb0c1625a213ab63667fb7f43037c906d870d4bf9982b4d0cee4\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/81/9f/43a031fce121c845baca1c5d9a1468cad98208286aa2832de9\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -e .\n",
        "!pip install mpi4py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This link will be used to access the web link. Noted: it will be available after the flask (the next two cells) has been successfully set up."
      ],
      "metadata": {
        "id": "z6AB7ZINBfVa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-cwEyWNOuQ0A",
        "outputId": "25d2aecc-dc43-4142-cf1d-4f4246594b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://m9o5q755maj-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"
          ]
        }
      ],
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP6qlTIzyXPi",
        "outputId": "6e20b741-7c31-4e22-af66-ecac151d0a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LMFlow/service\n"
          ]
        }
      ],
      "source": [
        "%cd service\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make sure to run this cell before access the above `https://xxxxxxxx.googleusercontent.com/`"
      ],
      "metadata": {
        "id": "lBpwXHwjLS_t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5f9Rxnrym6X",
        "outputId": "f9eb0329-9e8d-416d-d48c-f448fe2e15d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-05 03:07:08.731670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2023-04-05 03:08:09,273] [INFO] [comm.py:634:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
            "[2023-04-05 03:08:10,128] [INFO] [comm.py:688:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.28.0.12, master_port=29500\n",
            "[2023-04-05 03:08:10,128] [INFO] [comm.py:652:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2023-04-05 03:08:10,137] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown\n",
            "[2023-04-05 03:08:10,339] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "[2023-04-05 03:08:10,341] [INFO] [logging.py:93:log_dist] [Rank 0] Creating BF16 optimizer\n",
            "[2023-04-05 03:08:10,603] [INFO] [utils.py:829:see_memory_usage] begin bf16_optimizer\n",
            "[2023-04-05 03:08:10,604] [INFO] [utils.py:830:see_memory_usage] MA 5.13 GB         Max_MA 10.37 GB         CA 10.38 GB         Max_CA 10 GB \n",
            "[2023-04-05 03:08:10,605] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 6.43 GB, percent = 50.7%\n",
            "Using /root/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py39_cu118/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 1.166940689086914 seconds\n",
            "[2023-04-05 03:08:13,707] [INFO] [utils.py:829:see_memory_usage] end bf16_optimizer\n",
            "[2023-04-05 03:08:13,709] [INFO] [utils.py:830:see_memory_usage] MA 5.13 GB         Max_MA 5.13 GB         CA 10.38 GB         Max_CA 10 GB \n",
            "[2023-04-05 03:08:13,709] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 6.44 GB, percent = 50.8%\n",
            "[2023-04-05 03:08:13,711] [INFO] [config.py:1018:print] DeepSpeedEngine configuration:\n",
            "[2023-04-05 03:08:13,712] [INFO] [config.py:1022:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2023-04-05 03:08:13,712] [INFO] [config.py:1022:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2023-04-05 03:08:13,712] [INFO] [config.py:1022:print]   amp_enabled .................. False\n",
            "[2023-04-05 03:08:13,712] [INFO] [config.py:1022:print]   amp_params ................... False\n",
            "[2023-04-05 03:08:13,712] [INFO] [config.py:1022:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2023-04-05 03:08:13,712] [INFO] [config.py:1022:print]   bfloat16_enabled ............. True\n",
            "[2023-04-05 03:08:13,712] [INFO] [config.py:1022:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   checkpoint_tag_validation_enabled  True\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   checkpoint_tag_validation_fail  False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8090031400>\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   communication_data_type ...... None\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   curriculum_enabled_legacy .... False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   curriculum_params_legacy ..... False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   data_efficiency_enabled ...... False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   dataloader_drop_last ......... False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   disable_allgather ............ False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   dump_state ................... False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   dynamic_loss_scale_args ...... None\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   eigenvalue_enabled ........... False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   eigenvalue_layer_num ......... 0\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   eigenvalue_max_iter .......... 100\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   eigenvalue_stability ......... 1e-06\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   eigenvalue_tol ............... 0.01\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   eigenvalue_verbose ........... False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   elasticity_enabled ........... False\n",
            "[2023-04-05 03:08:13,713] [INFO] [config.py:1022:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   fp16_auto_cast ............... None\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   fp16_enabled ................. False\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   fp16_master_weights_and_gradients  False\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   global_rank .................. 0\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   grad_accum_dtype ............. None\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   gradient_accumulation_steps .. 1\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   gradient_clipping ............ 0.0\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   gradient_predivide_factor .... 1.0\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   initial_dynamic_scale ........ 1\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   load_universal_checkpoint .... False\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   loss_scale ................... 1.0\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   memory_breakdown ............. False\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   optimizer_legacy_fusion ...... False\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   optimizer_name ............... None\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   optimizer_params ............. None\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2023-04-05 03:08:13,714] [INFO] [config.py:1022:print]   pld_enabled .................. False\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   pld_params ................... False\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   prescale_gradients ........... False\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   scheduler_name ............... None\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   scheduler_params ............. None\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   sparse_attention ............. None\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   sparse_gradients_enabled ..... False\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   steps_per_print .............. 2000\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   train_batch_size ............. 1\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   train_micro_batch_size_per_gpu  1\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   use_node_local_storage ....... False\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   wall_clock_breakdown ......... False\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   world_size ................... 1\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   zero_allow_untested_optimizer  False\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   zero_enabled ................. False\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1022:print]   zero_optimization_stage ...... 0\n",
            "[2023-04-05 03:08:13,715] [INFO] [config.py:1007:print_user_config]   json = {\n",
            "    \"fp16\": {\n",
            "        \"enabled\": false\n",
            "    }, \n",
            "    \"bf16\": {\n",
            "        \"enabled\": true\n",
            "    }, \n",
            "    \"steps_per_print\": 2.000000e+03, \n",
            "    \"train_micro_batch_size_per_gpu\": 1, \n",
            "    \"wall_clock_breakdown\": false\n",
            "}\n",
            "Using /root/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.0005033016204833984 seconds\n",
            " * Serving Flask app 'app'\n",
            " * Debug mode: off\n",
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "127.0.0.1 - - [05/Apr/2023 03:14:00] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Apr/2023 03:14:00] \"GET /static/utils/vue-spinner.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Apr/2023 03:14:00] \"GET /static/assets/logo.png HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Apr/2023 03:14:01] \"GET /static/assets/logo.png HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Apr/2023 03:14:01] \"GET /static/assets/background.png HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Apr/2023 03:14:02] \"\u001b[33mGET /static/dist/assets/favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [05/Apr/2023 03:14:23] \"POST /predict HTTP/1.1\" 200 -\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python app.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell can be used to check your colab GPU type\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spAgig8_3ZsZ",
        "outputId": "835afdc9-0158-4469-a1b0-d39a8be42ff4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr  5 03:15:00 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}